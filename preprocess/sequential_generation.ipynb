{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed98c05e-dc3a-4f97-b75c-d507593e7243",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '2', '3', '4', '3', '5', '6', '3', '7', '8']\n",
      "350\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import random\n",
    "import os\n",
    "import collections\n",
    "\n",
    "# base_dir = \"/common/home/km1558/amazon_data/data\"\n",
    "base_dir = \"/common/home/km1558/rec_data/data\"\n",
    "\n",
    "# task = \"beauty\"\n",
    "\n",
    "# task = \"ml-1m\"\n",
    "\n",
    "# task = \"toys\"\n",
    "# task = \"taobao\"\n",
    "# task = \"lastfm\"\n",
    "task = \"yelp\"\n",
    "\n",
    "if task == \"sports\":\n",
    "    number_of_items = 18358\n",
    "elif task == \"beauty\":\n",
    "    number_of_items = 12102\n",
    "elif task == \"yelp\":\n",
    "    number_of_items = 20033\n",
    "\n",
    "with open(os.path.join(base_dir, task, \"remapped_sequential/data.txt\"), \"r\") as f:\n",
    "    data = f.read()\n",
    "\n",
    "data = data.split(\"\\n\")[:-1]\n",
    "data = {d.split(\" \")[0]: d.split(\" \")[1:] for d in data}\n",
    "\n",
    "\n",
    "all_train_sequence = [a for k, v in data.items() for a in v[:-2]]\n",
    "\n",
    "max_history = 0\n",
    "\n",
    "idx = 0\n",
    "print(all_train_sequence[:10])\n",
    "\n",
    "for k,v in data.items():\n",
    "    max_history = max(max_history, len(v))\n",
    "\n",
    "print(max_history)\n",
    "    \n",
    "all_sequence = [a for k, v in data.items() for a in v]\n",
    "\n",
    "# random_index = [i for i in range(1, number_of_items+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246254c5-4f9b-4be7-9b4c-486f2b781c7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# item2id = {}\n",
    "# sequential_data = []\n",
    "# user_idx = 1\n",
    "# item_idx = 1\n",
    "# with open(os.path.join(base_dir, task, \"data.txt\"), \"r\") as f:\n",
    "#     data = f.readlines()\n",
    "#     for useritem in data:\n",
    "#         useritem = useritem.replace(\"\\n\", \"\").split(\" \")\n",
    "#         items = useritem[1:]\n",
    "#         sequential_items = []\n",
    "#         for item in items:\n",
    "#             if item not in item2id.keys():\n",
    "#                 item2id[item] = str(item_idx)\n",
    "#                 item_idx += 1\n",
    "#             sequential_items.append(item2id[item])\n",
    "#         one_line = str(user_idx) + \" \" + \" \".join(sequential_items) + \"\\n\"\n",
    "#         sequential_data.append(one_line)\n",
    "#         user_idx += 1\n",
    "\n",
    "# with open(os.path.join(base_dir, task, \"sequential_data.txt\"), \"w\") as f:\n",
    "#     for sequences in sequential_data:\n",
    "#         f.write(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ac6d63-ef34-419f-b3ac-7ec61be7dbbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# item based random data\n",
    "# random_map = {}\n",
    "# random_data = {}\n",
    "# for user, items in data.items():\n",
    "#     new_items = []\n",
    "#     for item in items:\n",
    "#         if item not in random_map.keys():\n",
    "#             new_index = random.sample(random_index,k=1)[0]\n",
    "#             # print(new_index)\n",
    "#             random_map[item] = new_index\n",
    "#             random_index.remove(new_index)\n",
    "#         else:\n",
    "#             new_index = random_map[item]\n",
    "#         new_items.append(str(new_index))\n",
    "#     random_data[user] = new_items\n",
    "    \n",
    "# remapped_random_data = []\n",
    "# for k, v in random_data.items():\n",
    "#     one_line = k + \" \" + \" \".join(v) + \"\\n\"\n",
    "#     remapped_random_data.append(one_line)\n",
    "\n",
    "# print(remapped_random_data[:5])\n",
    "    \n",
    "# # generate time-sensitive sequential data\n",
    "# if not os.path.exists(os.path.join(base_dir, task, \"random\")):\n",
    "#     os.makedirs(os.path.join(base_dir, task, \"random\"))\n",
    "\n",
    "# with open(os.path.join(base_dir, task, \"random\", \"data.txt\"), \"w\") as f:\n",
    "#     for sequences in remapped_random_data:\n",
    "#         f.write(sequences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa31723c-150e-4b6a-bb75-177711bb0c30",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20034\n"
     ]
    }
   ],
   "source": [
    "# item based remapped sequential data\n",
    "remap = {}\n",
    "index = 1\n",
    "for item in all_train_sequence:\n",
    "    if item not in remap:\n",
    "        remap[item] = str(index)\n",
    "        index += 1\n",
    "for item in all_sequence:\n",
    "    if item not in remap:\n",
    "        remap[item] = str(index)\n",
    "        index += 1\n",
    "\n",
    "remapped_data = {}\n",
    "for k, v in data.items():\n",
    "    remapped_sequence = []\n",
    "    remapped_data[k] = [remap[a] for a in v]\n",
    "\n",
    "remapped_sequential_data = []\n",
    "for k, v in remapped_data.items():\n",
    "    one_line = k + \" \" + \" \".join(v) + \"\\n\"\n",
    "    remapped_sequential_data.append(one_line)\n",
    "\n",
    "# generate time-sensitive sequential data\n",
    "with open(os.path.join(base_dir, task, \"remapped_sequential\", \"data.txt\"), \"w\") as f:\n",
    "    for sequences in remapped_sequential_data:\n",
    "        f.write(sequences)\n",
    "\n",
    "print(index - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00bdeb77-c71a-4307-9b42-d68bccf5fb6b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['1', '1'], ['1', '2'], ['1', '3'], ['1', '4'], ['1', '3'], ['1', '5'], ['1', '6'], ['1', '3'], ['1', '7'], ['1', '8']]\n",
      "['1', '284', '521', '981', '1248', '1597', '1636', '2356', '2620', '3121', '3157', '3655', '3801', '3806', '3996', '4348', '4728', '4729', '5068', '5368', '5439', '5513', '6359', '6408', '6620', '6622', '6745', '7069', '7417', '7424', '7457', '7917', '8236', '8346', '8480', '8651', '8846', '8878', '9091', '9602', '9872', '11177', '11756', '11992', '12572', '12636', '12741', '13541', '13822', '14307', '14431', '14716', '14818', '15165', '15532', '15689', '16263', '16263', '16579', '17106', '17288', '17991', '18703']\n",
      "['1', '1', '1', '4228', '7486', '8303', '13147', '13183', '15132', '16879', '17446', '17458', '17460', '30017']\n",
      "['1', '1', '1', '1', '3432', '3774', '5995', '8512', '11543', '12963', '18154', '18456', '19866']\n",
      "['1', '1', '137', '832', '1141', '1372', '2253', '2253', '2656', '2656', '2865', '3477', '3823', '4262', '4367', '4367', '4790', '5035', '6597', '6916', '7376', '7508', '7571', '7686', '8802', '8837', '10483', '11437', '11660', '12002', '12044', '12115', '12802', '13040', '13404', '14270', '15166', '15458', '15458', '17193', '18176', '18207', '18883', '19702', '19939', '20447', '20771', '21311', '21500', '21534', '21558', '22944', '22969', '23527', '25537', '26332', '26473', '28381', '29102']\n",
      "['1', '1067', '1704', '6553', '7398', '8584', '14354', '15169', '15169', '16831', '17502', '18062', '18469']\n",
      "['1', '676', '2602', '5480', '5588', '6435', '6435', '7276', '7510', '10639', '10910', '10910', '12007', '14822', '16351']\n",
      "['1', '2222', '8121', '8547', '15823', '21689', '23990', '29069']\n",
      "['1', '1', '43', '4526', '5588', '11710', '16001', '17182', '17182', '19710', '22628', '24175', '24601', '27945', '29152']\n",
      "['1', '158', '1351', '1878', '3741', '3741', '5517', '6744', '8106', '9283', '10266', '11572', '11572', '12591', '13638', '17041', '17442', '18476', '21494', '23764', '28039', '28039', '29404']\n",
      "['1', '2253', '3350', '6852', '7424', '11043', '13807', '15659', '16001', '16591', '17264', '18482', '18879', '19015', '19028', '19545', '22840', '23344', '24476', '24476']\n"
     ]
    }
   ],
   "source": [
    "# user-based remapped sequential data\n",
    "\n",
    "with open(os.path.join(base_dir, task, \"remapped_sequential\", \"data.txt\"), \"r\") as f:\n",
    "    user_data = f.read()\n",
    "    user_data = user_data.split(\"\\n\")[:-1]\n",
    "\n",
    "useritems = []\n",
    "for d in user_data:\n",
    "    user = d.split(\" \")[0]\n",
    "    items = d.split(\" \")[1:]\n",
    "    for item in items:\n",
    "        useritems.append([user, item])\n",
    "\n",
    "print(useritems[:10])\n",
    "\n",
    "reverted_data = {}\n",
    "for [user, item] in useritems:\n",
    "    if item in reverted_data.keys():\n",
    "        reverted_data[item].append(user)\n",
    "    else:\n",
    "        reverted_data[item] = [user]\n",
    "\n",
    "sorted_reverted_data = collections.OrderedDict()\n",
    "\n",
    "for i in range(1, index):\n",
    "    sorted_reverted_data[str(i)] = reverted_data[str(i)]\n",
    "    if i <= 10:\n",
    "        print(reverted_data[str(i)])\n",
    "\n",
    "user_index = 1\n",
    "\n",
    "userid_map = {}\n",
    "\n",
    "reversed_userid_map = {}\n",
    "\n",
    "all_train_sequence = [a for k, v in sorted_reverted_data.items() for a in v[:-2]]\n",
    "all_sequence = [a for k, v in sorted_reverted_data.items() for a in v]\n",
    "\n",
    "for user in all_train_sequence:\n",
    "    if user not in userid_map:\n",
    "        userid_map[user] = str(user_index)\n",
    "        reversed_userid_map[str(user_index)] = user\n",
    "        user_index += 1\n",
    "        \n",
    "for user in all_sequence:\n",
    "    if user not in userid_map:\n",
    "        userid_map[user] = str(user_index)\n",
    "        reversed_userid_map[str(user_index)] = user\n",
    "        user_index += 1\n",
    "        \n",
    "user_remapped_data = {}\n",
    "for k, v in sorted_reverted_data.items():\n",
    "    remapped_sequence = []\n",
    "    user_remapped_data[k] = [userid_map[a] for a in v]\n",
    "\n",
    "remapped_sequential_data = []\n",
    "for k, v in user_remapped_data.items():\n",
    "    # if len(v) <= 5:\n",
    "    #     continue\n",
    "    one_line = k + \" \" + \" \".join(v) + \"\\n\"\n",
    "    remapped_sequential_data.append(one_line)\n",
    "\n",
    "if not os.path.exists(os.path.join(base_dir, task, \"user_CF_indices\")):\n",
    "    os.makedirs(os.path.join(base_dir, task, \"user_CF_indices\"))\n",
    "    \n",
    "# generate time-sensitive sequential data\n",
    "with open(os.path.join(base_dir, task, \"user_CF_indices\", \"data.txt\"), \"w\") as f:\n",
    "    for sequences in remapped_sequential_data:\n",
    "        f.write(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "511ff4d5-e2e5-4614-b0cc-22838de22a1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(base_dir, task, \"user_CF_indices\", \"userid_map.json\"), \"w\") as f:\n",
    "    json.dump(userid_map, f, indent=2)\n",
    "\n",
    "with open(os.path.join(base_dir, task, \"user_CF_indices\", \"reversed_userid_map.json\"), \"w\") as f:\n",
    "    json.dump(reversed_userid_map, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efa0ebf-670c-4366-86ec-5f687b4de44e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.9",
   "language": "python",
   "name": "py3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
