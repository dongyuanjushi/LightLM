{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "294ddfe4-b4ed-4491-8c05-7fec6e8df16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import os\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "import gzip\n",
    "from tqdm import tqdm\n",
    "import jsonlines\n",
    "import re\n",
    "\n",
    "def load_pickle(filename):\n",
    "    with open(filename, \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "\n",
    "def save_pickle(data, filename):\n",
    "    with open(filename, \"wb\") as f:\n",
    "        pickle.dump(data, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "def load_json(file_path):\n",
    "    with open(file_path, \"r\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "\n",
    "def ReadLineFromFile(path):\n",
    "    lines = []\n",
    "    with open(path, 'r') as fd:\n",
    "        for line in fd:\n",
    "            lines.append(line.rstrip('\\n'))\n",
    "    return lines\n",
    "\n",
    "\n",
    "def parse(path):\n",
    "    data = []\n",
    "    with gzip.open(path) as f:\n",
    "        for l in f:\n",
    "            data.append(json.loads(l.strip()))\n",
    "    return data\n",
    "\n",
    "def replace_multiple_spaces(text):\n",
    "    return re.sub(r'\\s+', ' ', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a194a342-af2e-4f10-b388-2b66792a99e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_amazon_data(dataset_name, rating_score):\n",
    "    '''\n",
    "    reviewerID - ID of the reviewer, e.g. A2SUAM1J3GNN3B\n",
    "    asin - ID of the product, e.g. 0000013714\n",
    "    reviewerName - name of the reviewer\n",
    "    helpful - helpfulness rating of the review, e.g. 2/3\n",
    "    --\"helpful\": [2, 3],\n",
    "    reviewText - text of the review\n",
    "    --\"reviewText\": \"I bought this for my husband who plays the piano. ...\"\n",
    "    overall - rating of the product\n",
    "    --\"overall\": 5.0,\n",
    "    summary - summary of the review\n",
    "    --\"summary\": \"Heavenly Highway Hymns\",\n",
    "    unixReviewTime - time of the review (unix time)\n",
    "    --\"unixReviewTime\": 1252800000,\n",
    "    reviewTime - time of the review (raw)\n",
    "    --\"reviewTime\": \"09 13, 2009\"\n",
    "    '''\n",
    "    datas = []\n",
    "    # older Amazon\n",
    "    data_file = '/common/home/km1558/amazon_data/' + 'reviews_' + dataset_name + '_5.json.gz'\n",
    "    # latest Amazon\n",
    "    # data_file = '/home/hui_wang/data/new_Amazon/' + dataset_name + '.json.gz'\n",
    "    parsed_data = parse(data_file)\n",
    "    \n",
    "    # add name for user\n",
    "    # for inter in parsed_data:\n",
    "    #     if \"reviewerName\" not in inter.keys():\n",
    "    #         continue\n",
    "    #     user_name = inter['reviewerName'].replace('\"','').replace(\",\", \"\")\n",
    "    #     user_name = replace_multiple_spaces(user_name)\n",
    "    #     if float(inter['overall']) <= rating_score:  # 小于一定分数去掉\n",
    "    #         continue\n",
    "    #     user = inter['reviewerID']\n",
    "    #     item = inter['asin']\n",
    "    #     time = inter['unixReviewTime']\n",
    "    #     datas.append((user, user_name, item, int(time)))\n",
    "    # return datas\n",
    "    for inter in parsed_data:\n",
    "        if float(inter['overall']) <= rating_score:  # 小于一定分数去掉\n",
    "            continue\n",
    "        user = inter['reviewerID']\n",
    "        item = inter['asin']\n",
    "        time = inter['unixReviewTime']\n",
    "        datas.append((user, item, int(time)))\n",
    "    return datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9e0a85be-34f1-49c2-8c5b-2ebd21be7618",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('A1YJEY40YUW4SE', '7806397051', 1391040000), ('A60XNB876KYML', '7806397051', 1397779200), ('A3G6XNM240RMWA', '7806397051', 1378425600), ('A1PQFP6SAJ6D80', '7806397051', 1386460800), ('A38FVHZTNQ271F', '7806397051', 1382140800), ('A3BTN14HIZET6Z', '7806397051', 1365984000), ('A1Z59RFKN0M5QL', '7806397051', 1376611200), ('AWUO9P6PL1SY8', '7806397051', 1378252800), ('A3LMILRM9OC3SA', '9759091062', 1405209600), ('A30IP88QK3YUIO', '9759091062', 1388102400)]\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"Beauty\"\n",
    "\n",
    "data = get_amazon_data(dataset_name, rating_score = 0)\n",
    "print(data[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "de85d1a7-e70a-4c80-9be8-fe214c10a5bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mode = \"user\"\n",
    "\n",
    "def get_interaction(datas):\n",
    "    user_seq = {}\n",
    "    \n",
    "    # add user name\n",
    "#     for data in datas:\n",
    "#         user, user_name, item, time = data\n",
    "#         user_plus_name = user + \":\" + user_name\n",
    "#         if user_plus_name in user_seq:\n",
    "#             user_seq[user_plus_name].append((item, time))\n",
    "#         else:\n",
    "#             user_seq[user_plus_name] = []\n",
    "#             user_seq[user_plus_name].append((item, time))\n",
    "    \n",
    "#     # print(user_seq.items())\n",
    "#     for user in user_seq.keys():\n",
    "#         item_time = user_seq[user]\n",
    "#         # item_time.sort(key=lambda x: x[1])  # 对各个数据集得单独排序\n",
    "#         items = []\n",
    "#         for t in item_time:\n",
    "#             items.append(t[0])\n",
    "#         user_seq[user] = items\n",
    "#     return user_seq\n",
    "    for data in datas:\n",
    "        # item, user, time = data\n",
    "        if mode == \"item\":\n",
    "            user, item, time = data\n",
    "        elif mode == \"user\":\n",
    "            item, user, time = data\n",
    "            \n",
    "        if user in user_seq:\n",
    "            user_seq[user].append((item, time))\n",
    "        else:\n",
    "            user_seq[user] = []\n",
    "            user_seq[user].append((item, time))\n",
    "    \n",
    "    # print(user_seq.items())\n",
    "    for user in user_seq.keys():\n",
    "        item_time = user_seq[user]\n",
    "        # item_time.sort(key=lambda x: x[1])  # 对各个数据集得单独排序\n",
    "        items = []\n",
    "        for t in item_time:\n",
    "            items.append(t[0])\n",
    "        # random.seed(123)\n",
    "        random.shuffle(items)\n",
    "        user_seq[user] = items\n",
    "        # print(user)\n",
    "        # print(items)\n",
    "    return user_seq\n",
    "    \n",
    "user_items = get_interaction(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b596ee56-0c01-4806-af96-08ff3563aec5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def check_Kcore(user_items, user_core, item_core):\n",
    "    user_count = defaultdict(int)\n",
    "    item_count = defaultdict(int)\n",
    "    for user, items in user_items.items():\n",
    "        for item in items:\n",
    "            user_count[user] += 1\n",
    "            item_count[item] += 1\n",
    "\n",
    "    for user, num in user_count.items():\n",
    "        if num < user_core:\n",
    "            return user_count, item_count, False\n",
    "    for item, num in item_count.items():\n",
    "        if num < item_core:\n",
    "            return user_count, item_count, False\n",
    "    return user_count, item_count, True  # 已经保证Kcore\n",
    "\n",
    "\n",
    "# 循环过滤 K-core\n",
    "def filter_Kcore(user_items, user_core, item_core):  # user 接所有items\n",
    "    user_count, item_count, isKcore = check_Kcore(user_items, user_core, item_core)\n",
    "    # for user in user_items:\n",
    "    #     if len(user_items[user]) >= 5:\n",
    "    #         print(user)\n",
    "    #         print(user_items[user])\n",
    "\n",
    "    while not isKcore:\n",
    "        for user, num in user_count.items():\n",
    "            if user_count[user] < user_core:  # 直接把user 删除\n",
    "                user_items.pop(user)\n",
    "            else:\n",
    "                for item in user_items[user]:\n",
    "                    if item_count[item] < item_core:\n",
    "                        user_items[user].remove(item)\n",
    "        user_count, item_count, isKcore = check_Kcore(user_items, user_core, item_core)\n",
    "    return user_items\n",
    "\n",
    "# user_items = filter_Kcore(user_items, 5, 5)\n",
    "\n",
    "# idx = 0\n",
    "# for user in user_items.keys():\n",
    "#     if idx >= 10:\n",
    "#         break\n",
    "#     idx += 1\n",
    "#     print(user)\n",
    "#     print(user_items[user])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7cbc3cb5-70d9-4e0b-859b-be28dcb9bf38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def id_map(user_items):  # user_items dict\n",
    "    user2id = {}  # raw 2 uid\n",
    "    item2id = {}  # raw 2 iid\n",
    "    id2user = {}  # uid 2 raw\n",
    "    id2item = {}  # iid 2 raw\n",
    "    user_id = 1\n",
    "    item_id = 1\n",
    "    final_data = {}\n",
    "    random_user_list = list(user_items.keys())\n",
    "    random.shuffle(random_user_list)\n",
    "    user_ids = [i for i in range(1, len(random_user_list) + 1)]\n",
    "    total_items = []\n",
    "    for user in random_user_list:\n",
    "        items = user_items[user]\n",
    "        for item in items:\n",
    "            if item not in total_items:\n",
    "                total_items.append(item)\n",
    "\n",
    "    item_nums = len(total_items)\n",
    "\n",
    "    item_ids = [i for i in range(1, item_nums + 1)]\n",
    "    final_data = {}\n",
    "\n",
    "    for user in random_user_list:\n",
    "        if user not in user2id:\n",
    "            user_index = random.randint(0, len(user_ids) - 1)\n",
    "            user_id = user_ids[user_index]\n",
    "            user2id[user] = str(user_id)\n",
    "            id2user[str(user_id)] = user\n",
    "            user_ids.remove(user_id)\n",
    "        iids = []  # item id lists\n",
    "        items = user_items[user]\n",
    "        for item in items:\n",
    "            if item not in item2id:\n",
    "                item_index = random.randint(0, len(item_ids) - 1)\n",
    "                item_id = item_ids[item_index]\n",
    "                item2id[item] = str(item_id)\n",
    "                id2item[str(item_id)] = item\n",
    "                item_ids.remove(item_id)\n",
    "            iids.append(item2id[item])\n",
    "        uid = user2id[user]\n",
    "        final_data[uid] = iids\n",
    "\n",
    "    # sequential data excluding evaluation and test dataset\n",
    "\n",
    "    data_maps = {\n",
    "        'user2id': item2id,\n",
    "        'item2id': user2id,\n",
    "        'id2user': id2item,\n",
    "        'id2item': id2user\n",
    "    }\n",
    "\n",
    "    return final_data, user_id - 1, item_id - 1, data_maps\n",
    "\n",
    "final_data, user_id, item_id, data_maps = id_map(user_items)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c2d81af8-2362-4a2c-be20-5e8475318fcd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "['1', '2', '3', '4', '5', '6', '5235', '3228']\n",
      "2\n",
      "['7', '8', '9', '10', '11', '12', '13', '14', '15', '10305', '14488']\n",
      "3\n",
      "['16', '17', '18', '7998', '20296']\n",
      "4\n",
      "['19', '20', '21', '22', '7491', '5649']\n",
      "5\n",
      "['23', '24', '25', '4753', '3606']\n",
      "6\n",
      "['26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '4475', '9950']\n",
      "7\n",
      "['46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '14932', '8550']\n",
      "8\n",
      "['67', '49', '68', '290', '14270']\n",
      "9\n",
      "['69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '81', '1115']\n",
      "10\n",
      "['80', '81', '82', '70', '71', '2654', '13796']\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "for user in final_data.keys():\n",
    "    idx += 1\n",
    "    if idx > 10:\n",
    "        break\n",
    "    print(user)\n",
    "    print(final_data[user])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a0e085d3-29e4-4af2-8eb1-9f14b26ae607",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_save_dir = \"/common/home/km1558/amazon_data/data\"\n",
    "\n",
    "import os\n",
    "\n",
    "task = \"beauty\"\n",
    "\n",
    "indexing = mode + \"_CF_indices\"\n",
    "\n",
    "save_dir = os.path.join(base_save_dir, task, indexing)\n",
    "\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "data_file = os.path.join(save_dir, \"data.txt\")\n",
    "\n",
    "with open(data_file, 'w') as out:\n",
    "    for user, items in final_data.items():\n",
    "        out.write(user + ' ' + ' '.join(items) + '\\n')\n",
    "\n",
    "datamaps_file = os.path.join(save_dir, mode + \"_CF_datamaps.json\")\n",
    "        \n",
    "json_str = json.dumps(data_maps, indent=2)\n",
    "with open(datamaps_file, 'w') as out:\n",
    "    out.write(json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08547de8-0e0f-4f63-a3d6-6176e970b622",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.9",
   "language": "python",
   "name": "py3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
